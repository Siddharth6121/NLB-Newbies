{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25982ad-f520-4fbd-b626-178375e6a15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8dd0e1-596e-4888-8b6d-1e1bd1ef3f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove numbers from text\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "def remove_unusual_characters(text):\n",
    "    res = re.sub(r'[^\\w\\s,.;:!?\\-]','',text)\n",
    "    res = re.sub(r'\\.+',' ',res)\n",
    "    res = re.sub(r'!+','',res)\n",
    "    res = re.sub(r',+',' ',res)\n",
    "    res = re.sub(r';+',' ',res)\n",
    "    res = re.sub(r';+',' ',res)\n",
    "    res = re.sub(r'\\n+','',res)\n",
    "    res = re.sub(r'\\d+','',res)\n",
    "    return re.sub(r'\\s+', ' ', res)\n",
    "\n",
    "\n",
    "    \n",
    "    return res\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6e0a4-78b0-483a-9370-8bf90afbf63e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"srl_sentiment_labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ae5dc-2452-43ac-9052-b587169e6e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224edd44-6621-4717-b06f-2d6cdaa90825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0808cf-b859-4175-a33c-132fe4659757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['Review','Label','sentiment','srl label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb8260-7ca5-46f4-bb12-3bd02ed568b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc82cc-81d3-411e-94ee-71b1a28262cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset='Review')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800b2b3-7fd5-480a-9f5a-35727fcc1d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].apply(remove_numbers)\n",
    "df['Review']=df['Review'].apply(remove_unusual_characters)\n",
    "df['Review']=df['Review'].apply(convert_to_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5fd412-09e4-466e-a0e7-2b8918a6a726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['Review'])\n",
    "sequences = tokenizer.texts_to_sequences(df['Review'])\n",
    "max_length = max(len(seq) for seq in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bf7ac-dca4-4f65-9550-5b35636f1e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43b62d-786d-4bf7-9f9e-095994a31847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "# Fit tokenizer on text\n",
    "tokenizer.fit_on_texts(df['Review'])\n",
    "\n",
    "# Convert text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(df['Review'])\n",
    "word_index = tokenizer.word_index\n",
    "print(f'Found {len(word_index)} unique tokens.')\n",
    "# Print sequences\n",
    "print(\"Tokenized sequences:\")\n",
    " \n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
    "type(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f0ae7-d8d4-4ca0-b06d-59e334c9b719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "srllabels=df['Label'].to_dict()\n",
    "for i in range(len(srllabels)):\n",
    "    srllabels[i] = ast.literal_eval(srllabels[i])\n",
    "\n",
    "srl = []\n",
    "# Assign indices for each label\n",
    "for i in range(len(srllabels)):\n",
    "    array = [0] * 33\n",
    "    for label, indices in srllabels[i].items():\n",
    "        if label == 'PRED':\n",
    "            for idx in indices:\n",
    "                array[idx] = 1\n",
    "        elif label == 'PROD1' or label == 'PROD2':\n",
    "            for idx in indices:\n",
    "                array[idx] = 2\n",
    "        elif label == 'ASP':\n",
    "            for idx in indices:\n",
    "                array[idx] = 3\n",
    "        #elif label == 'PROD2':\n",
    "        #    for idx in indices:\n",
    "        #        array[idx] = 4\n",
    "    srl.append(array)\n",
    "srl = np.array(srl)\n",
    "df['srl'] = [l for l in srl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4fbbe9-0a40-4991-8783-731c72690223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#not sure if we need this\n",
    "#results=[]\n",
    "#for seq,re in zip(padded_sequences,res):\n",
    "#    new_re = np.append(re, [0, 0])\n",
    "#    results.append(new_re)\n",
    "\n",
    "# print(results\n",
    "for seqi,rei in zip(padded_sequences,df['srl']): \n",
    "    print(len(seqi),len(rei))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb97f98-eaa4-4f76-b262-b58093d2d04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_seq_model = np.zeros((len(padded_sequences), len(padded_sequences[0]), 2))\n",
    "for i in range(len(padded_sequences)):\n",
    "    for j in range(len(padded_sequences[0])):\n",
    "        # print(i,j)\n",
    "        input_seq_model[i][j] = [padded_sequences[i][j], df['srl'][i][j]]\n",
    "        \n",
    "\n",
    "print(input_seq_model.shape)\n",
    "input_seq_model[0]\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60c520-f1d1-4ae3-9f68-57dd30f54c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label and encode ratings\n",
    "df_encoded = pd.get_dummies(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b04d7e5-6da9-4163-a71c-2361cd716569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the X and y values\n",
    "X = input_seq_model\n",
    "y = df_encoded.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44471f7-a50e-4bcd-aecd-b4499e085b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0464b05-e925-47dd-b035-b14c1de187d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import convert_to_tensor\n",
    "# Define validation set and convert to Tensor\n",
    "stop = int(len(X_test)/2)\n",
    "\n",
    "X_train = convert_to_tensor(X_train)\n",
    "X_val = convert_to_tensor(X_test[:stop])\n",
    "X_test = convert_to_tensor(X_test[stop:])\n",
    "\n",
    "y_train = convert_to_tensor(y_train)\n",
    "y_val = convert_to_tensor(y_test[:stop])\n",
    "y_test = convert_to_tensor(y_test[stop:])\n",
    "checkpoint_path = \"model_checkpoint.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                      monitor='val_accuracy',\n",
    "                                      save_best_only=True,\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d512d9b-ffb2-42c0-972e-de6121a7140b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Concatenate, Input\n",
    "from keras.models import Model\n",
    "\n",
    "# Assuming you have your data stored in variables padded_sequences and encoded_results\n",
    "padded_sequences_shape = (33,2)\n",
    "\n",
    "input1 = Input(shape = input_seq_model.shape[1:])\n",
    "# embedding_layer = Embedding(input_dim=6330,  # Replace vocabulary_size with your actual vocabulary size\n",
    "#                             output_dim=200,  # Replace embedding_dim with your desired embedding dimension\n",
    "#                             input_length=36)(input1)\n",
    "# Create the rest of the model\n",
    "x = LSTM(128,return_sequences = True)(input1)\n",
    "x = Dropout(0.5)(x)  # Add a dropout layer with a dropout rate of 0.5\n",
    "x = LSTM(128)(x)\n",
    "x = Dense(64,  activation='relu', \n",
    "          kernel_regularizer=regularizers.l2(0.01), \n",
    "          activity_regularizer=regularizers.l1(0.01))(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[input1], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34769bba-c77b-4b68-9fa6-e374ba60cd8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ace78-2093-4b23-833b-cfa2f60fb922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de78f19-108e-4296-b474-040aa2fb9c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming `model` is already trained and `X_test`, `y_test` are the test data\n",
    "# Make predictions\n",
    "model = load_model('SRL_Sentiment_model.h5')\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Convert predictions to classes\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# If your labels are one-hot encoded, you may want to convert them to integer labels\n",
    "y_true_classes = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Print the report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45458fd-d254-4a57-b056-fd9a36ff3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_NEWBIES",
   "language": "python",
   "name": "nlpnewbies"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
